Infrastructure:
  # Option 0: None (when pushing changes that should not run any workflows)
  Location: NoBench

  # Option 1: Minikube (local clone of this repo)
  Location: LocalMinikube

  # Option 2: LMCacheGKE (workflow will run on LMCache GPU runner)
  Location: LMCacheGKE
  numClusterGPUs: 1
  # numClusterGPUs: Only 1, 2, 4, 8 (A100 40GB) or 16 (A100 80GB) GPUs are supported.
  # 1 GPU -> 12 vCPUs, 85GB memory
  # 2 GPUs -> 24 vCPUs, 170GB memory
  # 4 GPUs -> 48 vCPUs, 340GB memory
  # 8 GPUs -> 96 vCPUs, 680GB memory
  # 16 GPUs -> 128 vCPUs, 1920GB memory

Serving:
  # Option 1: ProductionStack (with vllm v1)
  Baseline: ProductionStack
  ProductionStack:
    vLLM-Version: 0
    useLMCache: false
    enableChunkedPrefill: false # vllm v1 specific
    enablePrefixCaching: false # vllm v1 specific
    modelURL: meta-llama/Llama-3.1-8B-Instruct
    replicaCount: 1
    numGPUs: 1
    numCPUs: 4
    tensorParallelSize: 1
    hf_token: <YOUR_HF_TOKEN>
    maxModelLen: 16384

  # Option 2: SGLang
  Baseline: SGLang
  SGLang:
    modelURL: meta-llama/Llama-3.1-70B-Instruct
    hf_token: <YOUR_HF_TOKEN>
    # Coming soon...

  # Option 3: Dynamo
  Baseline: Dynamo
  Dynamo:
    # Coming soon...

Workload:
  # Multiple workloads can be specified and they will all be run.
  ShareGPT
    LIMIT: 1000
    MIN_ROUNDS: 10
    START_ROUND: 0
    QPS: [1.34, 2]

  LMCacheSynthetic
    NUM_USERS_WARMUP: 650
    NUM_USERS: 320
    NUM_ROUNDS: 20
    SYSTEM_PROMPT: 1000
    CHAT_HISTORY: 20000
    ANSWER_LEN: 100
    QPS: [0.1, 0.2, 0.3]

    # commonly used combinations:

    # long input long output:
    # NUM_USERS_WARMUP: 750
    # NUM_USERS: 350
    # NUM_ROUNDS: 20
    # SYSTEM_PROMPT: 0
    # CHAT_HISTORY: 20000
    # ANSWER_LEN: 1000
    # QPS: [0.7]

    # long input short output:
    # NUM_USERS_WARMUP: 20
    # NUM_USERS: 15
    # NUM_ROUNDS: 20
    # SYSTEM_PROMPT: 1000
    # CHAT_HISTORY: 20000
    # ANSWER_LEN: 100
    # QPS: [0.1]

    # short input short output:
    # NUM_USERS_WARMUP: 400
    # NUM_USERS: 320
    # NUM_ROUNDS: 20
    # SYSTEM_PROMPT: 0
    # CHAT_HISTORY: 256
    # ANSWER_LEN: 20
    # QPS: [15]

  Mooncake
    NUM_ROUNDS: 20
    SYSTEM_PROMPT: 0
    CHAT_HISTORY: 256
    ANSWER_LEN: 20
    QPS: [1]

    # commonly used combinations:
    # NUM_ROUNDS: 20
    # SYSTEM_PROMPT: 0
    # CHAT_HISTORY: 256
    # ANSWER_LEN: 20
    # QPS: [1]

  Agentic
    NUM_USERS_WARMUP: 100
    NUM_AGENTS: 10
    NUM_ROUNDS: 20
    SYSTEM_PROMPT: 0
    CHAT_HISTORY: 256
    ANSWER_LEN: 20
    QPS: [1]


