apiVersion: apps/v1
kind: Deployment
metadata:
  name: sglang-deployment
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app: sglang-server
  template:
    metadata:
      labels:
        app: sglang-server
        engine: sglang
    spec:
      restartPolicy: Always
      containers:
        - name: sglang-container
          image: docker.io/lmsysorg/sglang:latest
          imagePullPolicy: Always  # IfNotPresent or Never
          ports:
            - containerPort: 30000
          command: ["python3", "-m", "sglang.launch_server"]
          args: [
            "--model-path", "MODEL_URL_PLACEHOLDER",
            "--host", "0.0.0.0",
            "--port", "30000",
            "--context-length", "32768"
          ]
          env:
            - name: HF_TOKEN
              value: <YOUR_HF_TOKEN>
            - name: TRANSFORMERS_CACHE
              value: /huggingface-cache
          resources:
            requests:
              memory: "50Gi"
              nvidia.com/gpu: 1
            limits:
              nvidia.com/gpu: 1
          volumeMounts:
            - name: shm
              mountPath: /dev/shm
            - name: hf-cache
              mountPath: /huggingface-cache
            - name: localtime
              mountPath: /etc/localtime
              readOnly: true
          livenessProbe:
            httpGet:
              path: /health
              port: 30000
            initialDelaySeconds: 30
            periodSeconds: 10
      volumes:
        - name: shm
          emptyDir:
            medium: Memory
            sizeLimit: 10Gi
        - name: hf-cache
          emptyDir:
            sizeLimit: 20Gi
        - name: localtime
          hostPath:
            path: /etc/localtime
            type: File
---
apiVersion: v1
kind: Service
metadata:
  name: sglang-service
spec:
  selector:
    app: sglang-server
  ports:
    - protocol: TCP
      port: 30000  # port on host
      targetPort: 30000  # port in container
  type: LoadBalancer
