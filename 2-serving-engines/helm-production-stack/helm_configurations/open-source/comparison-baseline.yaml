servingEngineSpec:
  runtimeClassName: ""
  modelSpec:
  - name: "qwen3"
    repository: "lmcache/vllm-openai"
    tag: "latest"
    modelURL: "Qwen/Qwen3-32B"
    replicaCount: 4
    requestCPU: 10
    requestMemory: "70Gi"
    requestGPU: 2
    pvcStorage: "50Gi"
    pvcAccessMode:
      - ReadWriteOnce
    vllmConfig:
      enablePrefixCaching: true
      maxModelLen: 26000
      v1: 1
      tensorParallelSize: 2
      extraArgs:
        - "--tensor-parallel-size"
        - "2"
    lmcacheConfig:
      enabled: true
      cpuOffloadingBufferSize: "100"
    hf_token: <YOUR_HF_TOKEN>
    shmSize: "40Gi"

routerSpec:
  repository: "lmcache/lmstack-router"
  tag: "kvaware-latest"
  resources:
    requests:
      cpu: "1"
      memory: "2G"
    limits:
      cpu: "1"
      memory: "2G"
  routingLogic: "session"
  sessionKey: "x-user-id"