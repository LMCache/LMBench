Name: Open-Source-Comparison

# Suggested Infrastructure (in run-bench.yaml)
# 1-infrastructure:
#   Location: Local-Flat
#   Use 8x H100s or A100s (Make sure to set the correct acceleratorType in RayServe)
#   All deployments below use 4x Qwen-32B with tensor parallelism 2

Serving:
  # - Helm-ProductionStack:
  #     helmConfigSelection: open-source/comparison-baseline.yaml
  #     hf_token: <YOUR_HF_TOKEN>
  #     modelURL: Qwen/Qwen3-32B
  # - SGLang:
  #     scriptName: comparison-baseline.sh
  #     modelURL: Qwen/Qwen3-32B
  - RayServe:
      scriptName: comparison-baseline.py
      acceleratorType: H100
      modelURL: Qwen/Qwen3-14B
  # - LLM-D:
  #     configSelection: comparison-baseline.yaml
  #     modelURL: Qwen/Qwen3-32B
  #     hf_token: <YOUR_HF_TOKEN>
  # - Dynamo:
  #     configSelection: comparison-baseline.yaml
  #     modelURL: Qwen/Qwen3-14B

Workload:

  LMCacheSynthetic:
    # long input short output:
    - NUM_USERS_WARMUP: 30
      NUM_USERS: 60
      NUM_ROUNDS: 60
      SYSTEM_PROMPT: 1000
      CHAT_HISTORY: 20000
      ANSWER_LEN: 200
      QPS: [4]
      USE_SHAREGPT: false